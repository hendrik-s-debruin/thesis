\section{Path Planning}%
\label{sec:path_planning}

	A broad overview of path planning algorithms can be seen in
	Figure~\ref{fig:path_planning_overview}. Algorithms can be separated into
	discrete algorithms, which perform graph search over a discrete set of
	possible states, and continuous algorithms, which look for a path in an
	uncountable infinite search space. Continuous algorithms can further be
	subdivided into complete and incomplete algorithms. Complete algorithms are
	capable of finding a solution if one exists or reporting that there is no
	path in finite time. Incomplete algorithms cannot detect whether no path
	exists. Instead, they may run forever. If a path exists, the probability
	that the algorithm finds the path approaches unity as time approaches
	infinity.

	\begin{figure}[hb]
		\centering
		\def\svgwidth{\columnwidth}
		\import{res/img/}{path_planning_overview.pdf_tex}
		\caption{Path Planning Overview}%
		\label{fig:path_planning_overview}
	\end{figure}

	Path planning algorithms attempt to find a path $\pathsym$ that maps a
	position in the path $\timenorm$ into the free configuration space
	$\configurationspace_{\freeregion}$ of the system:

	\begin{equation}
		\pathsym : \timenorm \in [0, 1] \mapsto \configurationspace_{\freeregion}
	\end{equation}

	The free configuration space is defined in
	Section~\ref{sec:vector_spaces_in_path_planning}.


	\subsection{Vector Spaces in Path Planning}%
	\label{sec:vector_spaces_in_path_planning}

		Path planning deals with many different vector spaces. As such, an
		overview of these spaces is briefly given
		here~\cite{bib:planning:planning_algorithms}.

		The reachable world that a robot $\robot$ inhabits is denoted as
		$\world$. In general, the world is defined as $\world \subseteq \Re^3$,
		but for planar robots it is sufficient to assume $\world \subseteq
		\Re^2$.

		For any state $\state$ of the robot, an action $\action$ may be applied.
		In general, the set of actions that may be performed by the robot is
		dependent on the current robot state. These actions are collected in the
		action space $\actionspace(\state)$.

		The state transition function, $\statetransfunc$, changes the robot's
		state based on some action $\action\in\actionspace(\state)$:

		\begin{equation}
			\state' = \statetransfunc(\state, \action)
			\label{eq:state_transformation_function}
		\end{equation}

		A robot may be in a certain configuration $\configuration$. The position
		of a robot in the world is a function of the robot's configuration,
		$\robot(\configuration) \subset \world$. The configuration space is the
		set of configurations a robot can reach:

		\begin{equation}
			\configurationspace =
				\{
					\configuration | \configuration \in \text{joint limits of }
					\robot
				\}
		\end{equation}

		In general, the robot with $\robotdof$ degrees of freedom may be in
		collision with an obstacle or with itself. The obstacle configuration
		space is given by:

		\begin{equation}
			\configurationspace_{\obstacleregion} =
				\underbrace
				{%
					\left(
						\bigcup_{\indexi=1}^{\robotdof}
							\left\{
								\configuration \in \configurationspace |
									\robot_{\indexi}(\configuration) \cap \obstacle
									\neq \emptyset
							\right\}
					\right)
				}_{\text{collision with obstacle}}
				\bigcup
				\underbrace
				{%
					\left(
						\bigcup_{%
							\{\indexi, \indexj\} \in [1, \robotdof]
						}
						\left\{
							\configuration \in \configurationspace |
								\robot_{\indexi}(\configuration) \cap
								\robot_{\indexj}(\configuration)
								\neq \emptyset
						\right\}
					\right)
				}_{\text{self collision}}
			\label{eq:obstacle_configuration_space}
		\end{equation}

		For efficiency, pairs $\{\indexi, \indexj\}$ for which self collision
		are impossible may be omitted from the check in
		Equation~\ref{eq:obstacle_configuration_space}.

		The free configuration space is simply:

		\begin{equation}
			\configurationspace_{\freeregion} = \configurationspace \setminus
				\configurationspace_{\obstacleregion}
		\end{equation}

		The state $\state$ of a robot does not only contain its current
		configuration, but also its velocities and higher configuration
		derivatives $(\dot{\configuration},\cdots,\tdern{\configuration}{n})$.
		The phase space $\phasespace$ is the set of all possible states the
		robot may be in:

		\begin{equation}
			\phasespace =
				\left\{%
					\state |
						\state\, \text{does not violate maximum joint positions
						or velocities}
				\right\}
		\end{equation}

		The obstacle phase space $\phasespace_{\obstacleregion}$ is the set of
		states for which the robot is in collision. It is described by
		Equation~\ref{eq:obstacle_configuration_space}, replacing
		$\configurationspace$ with $\phasespace$.

		The region of inevitable collision
		$\phasespace_{\regionOfInevitableCollision}$ is the set of states that
		will lead to a collision, regardless of the input given to the system.
		This space is defined as:

		\begin{equation}
			\phasespace_{\regionOfInevitableCollision} =
				\left\{
					\state(0) \in \phasespace |
						\forall\action\in\actionspace,
							\exists\timesym > 0
					\suchthat
						\state(\timesym) \in \phasespace{\obstacleregion}
				\right\}
		\end{equation}

		Completely characterising this space remains an open problem, however.

	\subsection{Semi-Algebraic Representation of Bodies}%
	\label{sec:semi_algebraic_representation_of_bodies}

		A common way of representing a robot $\robot$ or an obstacle $\obstacle$
		is by the use of convex polyhedra
		\cite{bib:planning:planning_algorithms}. The following discussion will
		be based on obstacles, but the same representation can be made for a
		robot.

		A polyhedron may be built up by the use of a set of half-space
		primitives $\halfspaceprimitive$ that each define a face of the
		polyhedron. One face may be defined by using three non-collinear points
		of the plane and solving:

		\begin{equation}
			a\xcoord + b\ycoord + c\zcoord + d = 0
		\end{equation}

		By setting
		\(
			\function = a\xcoord + b\ycoord +c\zcoord + d
		\),
		a half-space primitive may be defined as the set of points:

		\begin{equation}
			\halfspaceprimitive_{\indexi} =
				\left\{
					(\xcoord,\ycoord,\zcoord) \in \world |
					\function_{\indexi}(\xcoord,\ycoord,\zcoord) \leq 0
				\right\}
				\label{eq:half_space_primitive}
		\end{equation}

		%Note here that $f_{\indexi}$ will be negative for the half-space that
		%contains the polyhedron.
		Now, a convex polyhedron obstacle may be
		defined as:

		\begin{equation}
			\obstacle_{\indexi} =
				\halfspaceprimitive_1 \cap \halfspaceprimitive_2 \cap \cdots \cap
				\halfspaceprimitive_{\cardinality{\obstacle_{\indexi}}}
				\label{eq:convex_obstacle}
		\end{equation}

		Finally, a non-convex polyhedron obstacle can be formed by the union of
		convex polyhedra:

		\begin{equation}
			\obstacle =
				\obstacle_1 \cup \obstacle_2 \cup \cdots \cup \obstacle_{\cardinality{\obstacle}}
				\label{eq:non_convex_obstacle}
		\end{equation}

		A polynomial function $\function(\xcoord,\ycoord,\zcoord)$ may also be
		used to define the primitive in Equation~\ref{eq:half_space_primitive}
		without changing the validity of the model. Furthermore, it is worth
		noting that other models, such as bitmaps, super quadratics and
		generalised cylinders may be used to represent obstacles. A short
		discussion on how to build these models can be found in~\cite[][page
		89]{bib:planning:planning_algorithms}.

		\subsubsection{Rigid-Body Transformation}%
		\label{sec:rigid_body_transformation}

			A robot $\robot$ is capable of undergoing rigid transforms. If the
			semi-algebraic model is used to parametrise a robot, such a
			transform must be reflected in the collection of primitives that
			make up the robot.

			In general, it is best to describe the primitives within the robot
			frame and not the world frame, that is,
			$\halfspaceprimitive_{\indexi} \in \robot \not\subset\world$~%
			\cite{bib:planning:planning_algorithms}. The
			robot may then be positioned in $\world$ by defining a transform
			function \transform:

			\begin{equation}
				\transform: \pointinrobot\in\robot \mapsto \point\in\world
			\end{equation}

			This function transforms the primitives of the robot in the
			following manner:

			\begin{equation}
				\transform(\halfspaceprimitive_{\indexi}) =
					\left\{
						\point \in \world |
							f_{\indexi}(\transform^{-1}(\point)) \leq 0
					\right\}
			\end{equation}

			This new collection of primitives serves to locate the robot in the
			world, $\robot\in\world$. For rigid robots, $\transform$ is often
			expressed with the well-known transformation matrices. However,
			simple function shifting techniques from calculus may also be used.
			An example of a translation function is simply:

			\begin{equation}
				\transform: (\xcoord, \ycoord, \zcoord) \mapsto (\xcoord +
				\Delta\xcoord, \ycoord + \Delta\ycoord, \zcoord + \Delta\zcoord)
			\end{equation}

		\subsubsection{Collision Detection}%
		\label{sec:collision_detection}

			The semi-algebraic model of
			Section~\ref{sec:semi_algebraic_representation_of_bodies} can be
			used to detect whether a point is in collision with an obstacle by
			use of a simple logical
			predicate~\cite{bib:planning:planning_algorithms}.

			Define, $\forall\halfspaceprimitive_{\indexi}$, a logical predicate
			\(
				\logicalpredicate_{\indexi}:
					\point\in\world \mapsto \{\true, \false\}
			\)
			such that~\cite{bib:planning:planning_algorithms}:

			\begin{equation}
				\logicalpredicate_{\indexi} =
					\begin{cases}
						\true, & f_{\indexi} \leq 0 \\
						\false, & f_{\indexi} > 0
					\end{cases}
			\end{equation}

			A point $\point$ can then be tested for collision with an obstacle
			$\obstacle$ using the predicate $\logicalpredicate$:

			\begin{equation}
				\logicalpredicate(\point) =
					\bigvee_{\obstacle_{\indexi} \in \obstacle}
						\left(
							\bigwedge_{\halfspaceprimitive_{\indexj} \in \obstacle_{\indexi}}
								\logicalpredicate_{\indexj}
						\right)
				=
				\begin{cases}
					\true,  &\point \in\obstacle \\
					\false, &\point \not\in \obstacle
				\end{cases}
				\label{eq:collision_point_with_obstacle}
			\end{equation}

			\paragraph{Hierarchical Collision Detection}%
			\label{sec:hierarchical_collision_detection}

				An efficient method to detect collision between bodies is to
				decompose the bodies into a tree structure. See
				Figure~\ref{fig:hierarchical_collision_detection_tree} for an
				example.

				\begin{figure}[htb]
					\centering
					\def\svgwidth{\columnwidth}
					\import{res/img/}{hierarchical_collision_detection.pdf_tex}
					\caption{Hierarchical Collision Detection Tree}%
					\label{fig:hierarchical_collision_detection_tree}
				\end{figure}

				The tree structure represents a type of two-phase collision
				detection. These phases are:

				\begin{enumerate}

					\item Broad phase:

						A simple bounding region, such as a sphere, is drawn
						around the object. Spheres are easy to check for
						collision, since they intersect if their centres are
						closer than the sum of their radii. As a second step of
						the broad phase, a bounding box may be drawn around the
						objects.

					\item Narrow phase:

						If the broad phase is not in collision, then the objects
						are definitely not in collision. However, if it is in
						collision, then one cannot yet determine the state of
						the objects.

						In this case, the objects are decomposed into smaller
						parts and the broad phase detection is applied to the
						component sections. As the tree deepens, narrower and
						narrower bounding regions are applied to the constituent
						objects.

						%At the leaves, the polygonal shapes described in
						%Section~\ref{sec:semi_algebraic_representation_of_bodies}
						%need to be checked for collision directly. An algorithm
						%to perform this detection can be found in\todo{put
						%reference to polygon collision detection algorithm
						%here}.

					\item Exact phase:

						As a final phase at the leaves of the tree, the objects
						may be checked exactly for collisions. This is more
						expensive than the previous phases. An algorithm to test
						for collisions between polyhedra can be found
						in~\cite{bib:planning:detecting_intersections_between_convex_polyhedra}.

				\end{enumerate}

			\paragraph{Path Segment Collision Detection}%
			\label{sec:path_segment_collision_detection}

				Hierarchical Collision Detection checks a single point of a
				path to ensure

				\begin{equation}
					\configuration \in \configurationspace_{\freeregion}
				\end{equation}

				However, there is the need to ensure that that a whole path is
				not in collision, that is:
				\begin{equation}
					\configuration \in
							\configurationspace_{\freeregion}
					\quad
						\forall\configuration\in\traj(\timenorm \in [0, 1])
				\end{equation}

				One method is to choose an increment $\Delta\configuration$, and
				then choose two points $(\traj(\timenorm_1),
				\traj(\timenorm_2))$ such that:

				\begin{equation}
					\norm
					{%
						\vecline
						{%
							\traj(\timenorm_1)
						}
						{%
							\traj(\timenorm_2)
						}
					}
					\leq
					\Delta\configuration
				\end{equation}

				Here, the line
				\(
					\vecline
					{%
						\traj(\timenorm_1)
					}
					{%
						\traj(\timenorm_2)
					}
				\)
				is taken along the trajectory $\traj$. If
				$\Delta\configuration$ is chosen correctly, then the absence of
				collision in $\traj(\timenorm_1)$ and $\traj(\timenorm_2)$ can
				guarantee that the segment
				\(
					\vecline
					{%
						\traj(\timenorm_1)
					}
					{%
						\traj(\timenorm_2)
					}
				\)
				is free of collisions.

				Furthermore, instead
				of testing the line in $\Delta\configuration$ increments from
				start to finish, it may be more efficient to perform a binary
				search over the line. This does not affect the case when there
				are no collisions, but tends to find collisions faster if they
				exist.

				The parameter $\Delta\configuration$ is often set
				experimentally. However, if the hierarchical collision detection
				algorithm is modified to return a distance $\distance$
				guaranteed to be smaller than the minimum distance between the
				bodies, then $\Delta\configuration$ inducing a transform
				$\transform(\robot)$ may be chosen such that:

				\begin{equation}
					\max_{\pointinrobot\in\robot}
					\left\{%
						\norm
						{%
							\pointinrobot - \transform(\pointinrobot)
						}
					\right\}
					\leq
					\distance
				\end{equation}

	%\subsection{Explicit Modelling of $\configurationspace_{\obstacleregion}$}%
	%\label{sec:explicit_modelling_of_obstacle_region_configuration_space}

	%	\todo{page 180 book}
	%	SECTION 4.3.3

	\subsection{Discrete Case}%
	\label{sec:discrete_case}

		Many motion planning problems reduce to graph search.
		Algorithm~\ref{alg:general_forward_search}~\cite[adapted
		from][]{bib:planning:planning_algorithms} illustrates the general
		framework to implement forward search in a graph.

		\begin{algorithm}[ht]
			\caption{General Forward Search}\label{alg:general_forward_search}
			\begin{algorithmic}[1]
				\Procedure{ForwardSearch}{$\state_{\initial}, \statespace_{\goal}$}

					\State{} $\queue\code{.Insert}(\state_{\initial})$
					\State{} mark $\state_{\initial}$ as visited.

					\While{$\queue \neq \emptyset$}

						\State{} $\state \gets \queue\code{.GetFirst}()$
						\If{$\state \in \statespace_{\goal}$}

							\State{} \textbf{return} \code{SUCCESS}

						\EndIf{}

						\ForAll{$\action \in \actionspace(\state)$}
							\State{} $\state' \gets \statetransfunc(\state, \action)$

							\If{$\state'$ not visited}
								\State{} Mark $\state'$ as visited
								\State{} $\queue\code{.Insert}(\state')$
							\Else{}
								\State{} Resolve duplicate $\state'$
							\EndIf{}
						\EndFor{}
					\EndWhile{}
					\State{} \textbf{Return} \code{FAILURE}
				\EndProcedure{}
			\end{algorithmic}
		\end{algorithm}

		The algorithm works by keeping a priority queue $\queue$ of active
		states. Every possible state can be either active, unvisited, or
		inactive. An active state is a visited state which has subsequent states
		that have not yet been visited, whereas an inactive state is a visited
		state for which all subsequent states have been visited.

		Each active state is $\state$ is expanded to find new states $\state'$
		by using the state transformation function,
		Equation~\ref{eq:state_transformation_function}.

		Sometimes the branching factor is lower when starting from the goal and
		working backwards towards the initial position.
		Algorithm~\ref{alg:general_forward_search} may be modified to a backward
		search by making the substitutions shown in
		Table~\ref{tab:switiching_between_forward_and_backward_search}.
		$\invaction$, $\invactionspace$ and $\invstatetransfunc$ are the inverse
		action, inverse action space and inverse state transformation functions,
		respectively.

		\begin{table}[ht]
			\centering
			\begin{tabular}{c  c}
				\toprule
				Forward Search 			& Backward Search\\
				\midrule
				$\state_{\initial}$		&	$\state_{\goal}$ 			\\
				$\statespace_{\goal}$	&	$\statespace_{\initial}$	\\
				$\action$ 				&	$\invaction$				\\
				$\actionspace$ 			&	$\invactionspace$			\\
				$\statetransfunc$ 		&	$\invstatetransfunc$		\\
				%\bottomrule
			\end{tabular}
			\caption{Switching Between Forward and Backward Search}%
			\label{tab:switiching_between_forward_and_backward_search}
		\end{table}


		Finally, it is worth noting that changing the type of priority queue
		$\queue$ in Algorithm~\ref{alg:general_forward_search} can be modified
		to obtain different types of search algorithms. For instance, Breadth
		First Search is obtained by setting $\queue$ to a \gls{fifo} queue,
		whereas Depth First Search may be obtained by setting $\queue$ to a
		stack~\cite[][page 35]{bib:planning:planning_algorithms}. The well-known
		Dijkstra and $A^*$ algorithms can be seen as specialisations of
		Algorithm~\ref{alg:general_forward_search}.

	\subsection{Continuous Case}%
	\label{sec:continuous_case}

		\subsubsection{Sampling-Based Motion Planning}%
		\label{sec:sampling_based_motion_planning}

			Sampling methods avoid explicit construction of
			$\configurationspace_{\obstacleregion}$. The idea is that they
			instead sample $\configurationspace$ while looking for a path. These
			algorithms cannot detect whether a path does not exist, and instead
			run forever.

			\paragraph{Sampling Strategies}%
			\label{sec:sampling_strategies}

				$\configurationspace$ may be sampled in different ways. As
				algorithms take sample of $\configurationspace$, they may build
				a topological graph \( \topologicalgraph(\vertex, \edge \in
				\configurationspace_{\freeregion}) \) which can be used with the
				algorithms from Section~\ref{sec:discrete_case} to obtain a path
				$\pathsym$.  Sampling strategies are required to produce dense
				samples as they progress in time.  What follows is a brief
				overview of possible sampling methods.

				\begin{itemize}

					\item Random Sampling

						This technique generates directions and orientations
						separately from different random distributions.  A
						random quaternion $\quaternion$ is generated from the
						formula\cite{bib:planning:planning_algorithms}:

						\begin{equation}
							\quaternion =
								\left(
									\sqrt
									{%
										1 - \gain_1
									}
									\sin
										2\pi \gain_2
									,
									\sqrt
									{%
										1 - \gain_1
									}
									\cos
										2\pi \gain_2
									,
									\sqrt
									{%
										\gain_1
									}
									\sin
										2\pi \gain_3
									,
									\sqrt
									{%
										\gain_1
									}
									\cos
										2\pi \gain_3
								\right)
						\end{equation}

						Where
						\(
							(\gain_1, \gain_2, \gain_3) \in [0, 1]
						\)
						are chosen from a uniform distribution.

						The components
						\(
							\point_1, \ldots, \point_n
						\)
						of a direction $\point$ may be drawn from a zero-mean
						Gaussian distribution. The direction is normalised with:

						\begin{equation}
							\point_{\mathrm{normalised}} =
								\frac{\point}{\norm{\point}}
						\end{equation}

						and is used to choose which direction to take a step in
						for the next sample.

					\item Low-Dispersion Sampling

						Low-Dispersion Sampling is a bit more sophisticated than
						Random Sampling. This technique tries to place the
						samples such that the largest uncovered area is
						minimised. Obviously, such samples cannot be perfectly
						random, but they tend to work better for motion
						planning.

						Optimal dispersion is produced by partitioning
						$\configurationspace$ into cubes and placing the sample
						at the centre of each cube. Given $\gain$ samples, the
						number of cubes per axis is then simply
						\(
							\floor*{\gain^{\frac{1}{\dim{\configurationspace}}}}
						\).

					%\item Low-Discrepancy Sampling

					%\item Incremental Sampling and Search

					\item Randomised Potential Fields

						Sampling techniques can get stuck in local minima.
						Randomised Potential Fields attempt to escape such
						minima.

						These algorithms have an attractive term which relates
						to the distance to $\configuration_{\goal}$, as well as
						a repulsive term which acts as a penalty on
						configurations that are too close to
						$\configurationspace_{\obstacleregion}$. The idea is
						that the algorithms perform a Best First Search search
						until they detect that they have gotten stuck. When this
						happens, the algorithm performs a random walk through
						$\configurationspace$ and  then performs Best First
						Search again. If the algorithm gets stuck too many
						times, it returns back to a random previous point
						$\configuration$ and starts over at this point.

						A negative point of such algorithms is that they tend to
						have a large amount of tuning parameters.

					\item \glspl{rdt}

						\glspl{rdt}~\cite{bib:planning:rapidly-exploring_random_trees_a_new_tool_for_path_planning}
						incrementally construct a tree in $\configurationspace$.
						The resolution of the tree increases as time progresses.
						This makes them analogous in a sense to space-filling
						curves. The well known \gls{rrt} algorithms can be
						considered as a special case of \glspl{rdt}. The basic
						\gls{rdt} algorithm is shown in
						Algorithm~\ref{alg:basic_rdt}.

						\begin{algorithm}[ht]
							\caption{Basic \gls{rdt} Algorithm}%
							\label{alg:basic_rdt}
							\begin{algorithmic}[1]
								\Procedure{BasicRDT}{$\configuration_{\initial}$}
									\State{} Initialise $\topologicalgraph$ with $\configuration_{\initial}$
									\While{$\configuration_{\goal}$ not reached}%
										\State{} $\sample \gets \code{SAMPLE}(\configurationspace)$ 								\label{alg:basic_rdt:sample}%
										\State{} $\configuration_1 \gets \code{NEAREST}(\swath(\topologicalgraph),\sample)$ 		\label{alg:basic_rdt:nearest}%
										\State{} $\configuration_2 \gets \code{STOP\_CONFIGURATION}(\configuration_1, \sample)$ 	\label{alg:basic_rdt:stop}%
										\If{$\configuration_1 \neq \configuration_2$}%
											\State{} $\topologicalgraph$.\code{add\_vertex}$(\configuration_2)$ 					\label{alg:basic_rdt:add_vertex}%
											\State{} $\topologicalgraph$.\code{add\_edge}$(\configuration_1, \configuration_2)$ 	\label{alg:basic_rdt:add_edge}%
										\EndIf{}
									\EndWhile{}
								\EndProcedure{}
							\end{algorithmic}
						\end{algorithm}

						The algorithm attempts to connect a sample
						$\sample\in\configurationspace$ to the nearest point
						$\configuration_1$ in the swath of the topological
						graph, $\swath(\topologicalgraph)$, in
						Line~\ref{alg:basic_rdt:nearest}. Note that this may add
						a new vertex to $\topologicalgraph$ if
						$\configuration_1$ is closer to an edge
						$\edge\in\topologicalgraph$ than a vertex
						$\vertex\in\topologicalgraph$.
						Line~\ref{alg:basic_rdt:stop} picks a point
						$\configuration_2$ along the direction
						$\vecline{\configuration_1}{\sample}$ as close as
						possible to $\sample$, but stopping short of any
						obstacles. This point is then added to
						$\topologicalgraph$.

				\end{itemize}

			\paragraph{Connecting $\configuration_{\initial}$ and
			$\configuration_{\goal}$ to the grid}%
			\label{sec:connecting_initial_configuration_and_goal_configuration_to_the_grid}

				Sampled points are not likely to coincide directly with
				$\configuration_{\initial}$ or $\configuration_{\goal}$.
				Instead, a region around these points must be chosen. The points
				are connected to any sampled points in this region using a
				method such as that described in
				Section~\ref{sec:path_segment_collision_detection}. The size of
				this region can for instance be based on the greatest distance
				between a sampled point and its farthest neighbour.

			\paragraph{Smoothing Random Paths}%
			\label{sec:smoothing_random_paths}

				Random sampling will tend to lead to jagged paths. A path
				$\pathsym$ may be smoothed to obtain $\pathsym'$ by choosing two
				points in the original path and smoothly merging them. This is
				achieved with the following formula, for
				instance~\cite{bib:planning:planning_algorithms}:

				\begin{equation}
					\pathsym'(\timenorm) =
						\begin{cases}
							\pathsym(\timenorm) & \timenorm\in[0, \timenorm_1]\\
							%
							\relweight\pathsym(\timenorm_1) +
								(1-\relweight)\pathsym(\timenorm_2)
							& \timenorm\in(\timenorm_1,\timenorm_2)\\
							%
							\pathsym(\timenorm) & \timenorm\in[\timenorm_2, 1]\\
						\end{cases}
				\end{equation}
		\subsubsection{Combinatorial Motion Planning}%
		\label{sec:combinatorial_motion_planning}

			Combinatorial motion planning
			methods~%
			\cite{bib:planning:planning_algorithms}%
			\cite{bib:planning:robot_motion_planning}
			differ from the
			sampling-based methods of
			Section~\ref{sec:sampling_based_motion_planning} in that they are
			complete algorithms. That is, these algorithms are guaranteed to
			find a path in finite time if it exists, or report that no path
			exists.

			These algorithms work by decomposing $\configurationspace$ into
			cells $\cell$ that are guaranteed to be free from collisions. That
			is, the algorithms guarantee that:

			\begin{equation}
				\point\in\configurationspace_{\freeregion},
				\quad
				\forall\point\in\cell \, \text{and} \, \forall\cell\in\configurationspace
			\end{equation}

			An example cell decomposition for $\configurationspace\subseteq\Re^2$ can be seen
			in Figure~\ref{fig:example_2d_cell_decomposition}.

			\begin{figure}[hb]
				\centering
				\def\svgwidth{\columnwidth}
				\import{res/img/}{2d_cell_decomposition.pdf_tex}
				\caption[Example 2D Cell Decomposition]
				{%
					Example 2D Cell Decomposition
					(adapted from~\cite[][page 269]
						{bib:planning:planning_algorithms})
				}%
				\label{fig:example_2d_cell_decomposition}
			\end{figure}

			The connectivity of the cells is encapsulated in a graph
			$\topologicalgraph$ which may be searched for paths using the
			methodologies of Section~\ref{sec:discrete_case}.

			It should be noted that~\cite{bib:planning:planning_algorithms}
			warns that combinatorial motion planning methods may be impractical
			in practice. They are also not suitable for differential
			constraints.  As such, they are not explored further in this report.
			However, a good reference for such algorithms can be found
			in~\cite{bib:planning:robot_motion_planning}.

	\subsection{Planning in the Presence of Differential Constraints}%
	\label{sec:planning_in_the_presence_of_differential_constraints}

		Planning may be subject to differential constraints. Such constraints
		are often expressed in an implicit form:

		\begin{equation}
			g(\configuration, \dot{\configuration}, \ldots, \tdern{\configuration}{n})
				\relop 0
			\label{eq:implicit_dif_constraint}
		\end{equation}

		Where $\relop$ represents an operator in the set \ensuremath{\{<, \leq,
		=, \geq, >\}}.  Such a constraint may for instance indicate that the
		velocity may not exceed a certain threshold. In such a case,
		equation~\ref{eq:implicit_dif_constraint} takes the form
		$\norm{\dot{\configuration}} < \threshold$.  However, planning
		algorithms require differential constraints to be expressed in the
		parametric form:

		\begin{equation}
			\dot{\configuration} = f(\configuration, \action)
			\label{eq:parameteric_dif_constraint}
		\end{equation}

		The state-space representation techniques from control theory may be
		used to convert the representation in
		Equation~\ref{eq:implicit_dif_constraint} to that in
		Equation~\ref{eq:parameteric_dif_constraint}. As a simple example,
		consider $k$ equations of the form:

		\begin{equation}
			g_1(\configuration_1)\dot{\configuration}_1 + \cdots +
				g_n(\configuration_n)\dot{\configuration}_n
			=
			0
		\end{equation}

		These may be converted to the form in
		Equation~\ref{eq:parameteric_dif_constraint} by making the
		substitutions:

		\begin{align}
				\dot{\configuration_{\indexi}} &= \action_{\indexi} 					\quad&&\forall\indexi\in [1, \dim{\configurationspace} - k] \\
				\dot{\configuration_{\indexi}} &= f_{\indexi}(\configuration, \action)	\quad&&\forall\indexi\in [\dim{\configurationspace} - k + 1,\dim\configurationspace]
		\end{align}

		Where $f_{\indexi}$ is found by simply solving the functions for
		$\dot{\configuration_{\indexi}}$.

		\subsubsection{Use of Phase Space}%
		\label{sec:use_of_phase_space}

			When higher-order differential constraints are imposed on the
			problem, it is of benefit to express the system in phase space
			$\phasespace$ instead of configuration space $\configurationspace$.
			In general, the relation between the dimensions of these spaces is
			given by:

			\begin{equation}
				\dim\phasespace = k\dim\configurationspace
			\end{equation}

			Where $k$ is the highest-order of the differential constraints.

		\subsubsection{Sampling Approaches}%
		\label{sec:sampling_approaches}

			One approach to path planning with differential constraints requires
			the selection of a discrete set of motion primitives:

			\begin{equation}
				\actionspace_{\discrete} \subset \actionspace
			\end{equation}

			To each action $\action_{\discrete} \in \actionspace_{\discrete}$ is
			associated a time duration $\timesym_{\discrete}$.

			To find successive states, sampling algorithms use the discrete
			state transition function:

			\begin{equation}
				\state_{\indexk + 1} = f_{\discrete}(\state_{\indexk},
					{\action_{\discrete}}_{\indexk})
			\end{equation}

			Therefore, the sampling algorithm needs to sample both $\phasespace$
			and $\actionspace$. The methods mentioned in
			Section~\ref{sec:sampling_based_motion_planning} are generally used
			to sample these spaces.

			Collision detection from Section~\ref{sec:collision_detection} is
			used to test these samples. However, the phase constraints need to
			be tested separately. Since
			$\phasespace_{\regionOfInevitableCollision}$ cannot be checked
			directly, the general method is to test that a state $\state$ is
			farther than some threshold $\threshold$ from each constraint
			boundary.

			In practice, \gls{rdt} methods tend to return feasible trajectories
			in phase space with relatively few samples. However, these paths
			tend to be suboptimal.



