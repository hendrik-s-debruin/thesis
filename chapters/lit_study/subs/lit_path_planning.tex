\section{Path Planning}%
\label{sec:path_planning}

	\todo{talk about the things mentioned here}

	Complete algorithms

	Incomplete algorithms

	\todo{discuss path here}
	DISCUSS THIS

	\begin{equation}
		\pathsym : \timenorm \in [0, 1] \mapsto \configurationspace_{\freeregion}
	\end{equation}

	\subsection{Vector Spaces in Motion Planning}%
	\label{sec:vector_spaces_in_motion_planning}

		\todo{Talk about the things here}

		The reachable world the robot inhabits is denoted as $\world$. In
		general it is defined as $\world \subseteq \Re^3$, but for planar robots
		it is sufficient to assume $\world \subseteq \Re^2$.

		State space $\statespace$.

		Phase Space $\phasespace$.

		The region of inevitable collision
		$\phasespace_{\regionOfInevitableCollision}$ is the set of states that
		will lead to a collision, regardless of the input given to the system.
		This space is defined as:

		\begin{equation}
			\phasespace_{\regionOfInevitableCollision} =
				\left\{
					\state(0) \in \phasespace |
						\forall\action\in\actionspace,
							\exists\timesym > 0
					\suchthat
						\state(\timesym) \in \phasespace{\obstacleregion}
				\right\}
		\end{equation}

		Completely characterising this space remains an open problem, however.

		Action space $\actionspace(\state)$

		The position of a robot in space is a function of the robot's
		configuration, $\robot(\configuration) \subset \world$. The
		configuration space is the set of configurations a robot can reach:

		\begin{equation}
			\configurationspace =
				\{
					\configuration | \configuration \in \text{joint limits of }
					\robot
				\}
		\end{equation}

		In general, the robot with $\robotdof$ degrees of freedom may be in
		collision with an obstacle or with itself. The obstacle configuration
		space is given by:

		\begin{equation}
			\configurationspace_{\obstacleregion} =
				\underbrace
				{%
					\left(
						\bigcup_{\indexi=1}^{\robotdof}
							\left\{
								\configuration \in \configurationspace |
									\robot_{\indexi}(\configuration) \cap \obstacle
									\neq \emptyset
							\right\}
					\right)
				}_{\text{collision with obstacle}}
				\bigcup
				\underbrace
				{%
					\left(
						\bigcup_{%
							\{\indexi, \indexj\} \in [1, \robotdof]
						}
						\left\{
							\configuration \in \configurationspace |
								\robot_{\indexi}(\configuration) \cap
								\robot_{\indexj}(\configuration)
								\neq \emptyset
						\right\}
					\right)
				}_{\text{self collision}}
			\label{eq:obstacle_configuration_space}
		\end{equation}

		For efficiency, pairs $\{\indexi, \indexj\}$ for which self collision
		are impossible may be omitted from the check in
		Equation~\ref{eq:obstacle_configuration_space}.

		The free configuration space is simply:

		\begin{equation}
			\configurationspace_{\freeregion} = \configurationspace \setminus
				\configurationspace_{\obstacleregion}
		\end{equation}

	\subsection{Semi-Algebraic Representation of Bodies}%
	\label{sec:semi_algebraic_representation_of_bodies}

		A common way of representing a robot $\robot$ or obstacle $\obstacle$ is
		by the use of convex polyhedra. The following discussion will be based
		on obstacles, but the same representation can be made for a robot.

		A polyhedron may be built up by the use of a set of half-space
		primitives $\halfspaceprimitive$ that each define a face of the
		polyhedron. One face may be defined by using three non-collinear points
		of the plane and solving:

		\begin{equation}
			ax + by + cz + d = 0
		\end{equation}

		By setting
		\(
			f = ax + by +cz + d
		\),
		a half-space primitive may be defined as the set of points:

		\begin{equation}
			\halfspaceprimitive_{\indexi} =
				\left\{
					(x,y,z) \in \world |
					f_{\indexi}(x,y,z) \leq 0
				\right\}
				\label{eq:half_space_primitive}
		\end{equation}
		\todo{some of these are not in the nomenclature}

		%Note here that $f_{\indexi}$ will be negative for the half-space that
		%contains the polyhedron.
		Now, a convex polyhedron obstacle may be
		defined as:

		\begin{equation}
			\obstacle_{\indexi} =
				\halfspaceprimitive_1 \cap \halfspaceprimitive_2 \cap \cdots \cap
				\halfspaceprimitive_{\cardinality{\obstacle_{\indexi}}}
				\label{eq:convex_obstacle}
		\end{equation}

		Finally, a non-convex polyhedron obstacle can be formed by the union of
		convex polyhedra:

		\begin{equation}
			\obstacle =
				\obstacle_1 \cup \obstacle_2 \cup \cdots \cup \obstacle_{\cardinality{\obstacle}}
				\label{eq:non_convex_obstacle}
		\end{equation}

		A polynomial function $f(x,y,z)$ may also be used to define the
		primitive in Equation~\ref{eq:half_space_primitive} without changing the
		validity of the model. Furthermore, it is worth noting that other
		models, such as bitmaps, super quadratics and generalised cylinders may
		be used to represent obstacles. A short discussion on how to build these
		models can be found in~\cite[][page
		89]{bib:planning:planning_algorithms}.

		\subsubsection{Rigid-Body Transformation}%
		\label{sec:rigid_body_transformation}

			A robot $\robot$ is capable of undergoing rigid transforms. If the
			semi-algebraic model is used to parametrise a robot, such a
			transform must be reflected in the collection of primitives that
			make up the robot.

			In general, it is best to describe the primitives within the robot
			frame and not the world frame, that is,
			$\halfspaceprimitive_{\indexi} \in \robot \not\subset\world$. The
			robot may then be positioned in $\world$ by defining a transform
			function \transform:

			\begin{equation}
				\transform: \pointinrobot\in\robot \mapsto \point\in\world
			\end{equation}

			This function transforms the primitives of the robot in the
			following manner:

			\begin{equation}
				\transform(\halfspaceprimitive_{\indexi}) =
					\left\{
						\point \in \world |
							f_{\indexi}(\transform^{-1}(\point)) \leq 0
					\right\}
			\end{equation}

			This new collection of primitives serves to locate the robot in the
			world, $\robot\in\world$. For rigid robots, $\transform$ is often
			expressed with the well-known transformation matrices. However,
			simple function shifting techniques from calculus may also be used.
			An example of a translation function is simply:

			\begin{equation}
				\transform: (x, y, z) \mapsto (x + \Delta x, y + \Delta y, z + \Delta z)
			\end{equation}

		\subsubsection{Collision Detection}%
		\label{sec:collision_detection}

			The semi-algebraic model of
			Section~\ref{sec:semi_algebraic_representation_of_bodies} can be
			used to detect whether a point is in collision with an obstacle by
			use of a simple logical predicate.

			Define, $\forall\halfspaceprimitive_{\indexi}$, a logical predicate
			\(
				\logicalpredicate_{\indexi}:
					\point\in\world \mapsto \{\true, \false\}
			\)
			such that:

			\begin{equation}
				\logicalpredicate_{\indexi} =
					\begin{cases}
						\true, & f_{\indexi} \leq 0 \\
						\false, & f_{\indexi} > 0
					\end{cases}
			\end{equation}

			A point $\point$ can then be tested for collision with an obstacle
			$\obstacle$ using the predicate $\logicalpredicate$:

			\begin{equation}
				\logicalpredicate(\point) =
					\bigvee_{\obstacle_{\indexi} \in \obstacle}
						\left(
							\bigwedge_{\halfspaceprimitive_{\indexj} \in \obstacle_{\indexi}}
								\logicalpredicate_{\indexj}
						\right)
				=
				\begin{cases}
					\true,  &\point \in\obstacle \\
					\false, &\point \not\in \obstacle
				\end{cases}
			\end{equation}

			\paragraph{Hierarchical Collision Detection}%
			\label{sec:hierarchical_collision_detection}

				An efficient method to detect collision between bodies is to
				decompose the bodies into a tree structure. See
				Figure~\ref{fig:hierarchical_collision_detection_tree} for an
				example.

				\begin{figure}[hb]
					\centering
					\def\svgwidth{\columnwidth}
					\import{res/img/}{hierarchical_collision_detection.pdf_tex}
					\caption{Hierarchical Collision Detection Tree}%
					\label{fig:hierarchical_collision_detection_tree}
				\end{figure}

				The tree structure represents a type of two-phase collision
				detection. These phases are:

				\begin{enumerate}

					\item Broad phase:

						A simple bounding region, such as a sphere, is drawn
						around the object. Spheres are easy to check for
						collision, since they intersect if their centres are
						closer than the sum of their radii. As a section step of
						the broad phase, a bounding box may be drawn around the
						objects.

					\item Narrow phase:

						If the broad phase is not in collision, then the objects
						are definitely not in collision. However, if it is in
						collision, then one cannot yet determine the state of
						the objects.

						In this case, the objects are decomposed into smaller
						parts and the broad phase detection is applied to the
						component sections. As the tree deepens, narrower and
						narrower bounding regions are applied to the constituent
						objects.

						%At the leaves, the polygonal shapes described in
						%Section~\ref{sec:semi_algebraic_representation_of_bodies}
						%need to be checked for collision directly. An algorithm
						%to perform this detection can be found in\todo{put
						%reference to polygon collision detection algorithm
						%here}.

					\item Exact phase:

						As a final phase at the leaves of the tree, the objects
						may be checked exactly for collisions. This is more
						expensive than the previous phases. An algorithm to test
						for collisions between polyhedra can be found
						in~\cite{bib:planning:detecting_intersections_between_convex_polyhedra}.

				\end{enumerate}

			\paragraph{Path Segment Collision Detection}%
			\label{sec:path_segment_collision_detection}

				Hierarchical Collision Detection checks a single point to ensure

				\begin{equation}
					\configuration \in \configurationspace_{\freeregion}
				\end{equation}

				However, there is the need to ensure that that a whole path is
				not in collision, that is:
				\begin{equation}
					\configuration \in
						\traj(\timenorm \in [0, 1])
							\in \configurationspace_{\freeregion}
				\end{equation}

				One method is to choose an increment $\Delta\configuration$, and
				then choose two points $(\traj(\timenorm_1),
				\traj(\timenorm_2))$ such that:

				\begin{equation}
					\norm
					{%
						\vecline
						{%
							\traj(\timenorm_1)
						}
						{%
							\traj(\timenorm_2)
						}
					}
					\leq
					\Delta\configuration
				\end{equation}

				Here, the line
				\(
					\vecline
					{%
						\traj(\timenorm_1)
					}
					{%
						\traj(\timenorm_2)
					}
				\)
				is taken along the trajectory $\traj$. If
				$\Delta\configuration$ is chosen correctly, then the absence of
				collision in $\traj(\timenorm_1)$ and $\traj(\timenorm_2)$ can
				guarantee that the segment
				\(
					\vecline
					{%
						\traj(\timenorm_1)
					}
					{%
						\traj(\timenorm_2)
					}
				\)
				is free of collisions.

				Furthermore, instead
				of testing the line in $\Delta\configuration$ increments from
				start to finish, it may be more efficient to perform a binary
				search over the line. This does not affect the case when there
				are no collisions, but tends to find collisions faster if they
				exist.

				The parameter $\Delta\configuration$ is often set
				experimentally. However, if the hierarchical collision detection
				algorithm is modified to return a distance $\distance$
				guaranteed to be smaller than the minimum distance between the
				bodies, then $\Delta\configuration$ inducing a transform
				$\transform(\robot)$ may be chosen such that:

				\begin{equation}
					\max_{\pointinrobot\in\robot}
					\left\{%
						\norm
						{%
							\pointinrobot - \transform(\pointinrobot)
						}
					\right\}
					\leq
					\distance
				\end{equation}

	\subsection{Explicit Modelling of $\configurationspace_{\obstacleregion}$}%
	\label{sec:explicit_modelling_of_obstacle_region_configuration_space}

		\todo{page 180 book}
		SECTION 4.3.3

	\subsection{Discrete Case}%
	\label{sec:discrete_case}

		\todo{in this section, f is not in the nomenclature}

		Many motion planning problems reduce to graph search.
		Algorithm~\ref{alg:general_forward_search}\cite[adapted
		from][]{bib:planning:planning_algorithms} illustrates the general
		framework to implement forward search in a graph.

		\begin{algorithm}[ht]
			\caption{General Forward Search}\label{alg:general_forward_search}
			\begin{algorithmic}[1]
				\Procedure{ForwardSearch}{$\state_{\initial}, \statespace_{\goal}$}

					\State{} $\queue\code{.Insert}(\state_{\initial})$
					\State{} mark $\state_{\initial}$ as visited.

					\While{$\queue \neq \emptyset$}

						\State{} $\state \gets \queue\code{.GetFirst}()$
						\If{$\state \in \statespace_{\goal}$}

							\State{} \textbf{return} \code{SUCCESS}

						\EndIf{}

						\ForAll{$\action \in \actionspace(\state)$}
							\State{} $\state' \gets f(\state, \action)$

							\If{$\state'$ not visited}
								\State{} Mark $\state'$ as visited
								\State{} $\queue\code{.Insert}(\state')$
							\Else{}
								\State{} Resolve duplicate $\state'$
							\EndIf{}
						\EndFor{}
					\EndWhile{}
					\State{} \textbf{Return} \code{FAILURE}
				\EndProcedure{}
			\end{algorithmic}
		\end{algorithm}

		The algorithm works by keeping a priority queue $\queue$ of active
		states. Every possible state can be either active, unvisited, or
		inactive. An active state is a visited state which has subsequent states
		that have not yet been visited, whereas an inactive state is a visited
		state for which all subsequent states have been visited.

		Each active state is $\state$ is expanded to find new states $\state'$
		by using the action $\action$ as follows:

		\begin{equation}
			\state' = f(\state, \action)
		\end{equation}

		Sometimes the branching factor is lower when starting from the goal and
		working backwards towards the initial position.
		Algorithm~\ref{alg:general_forward_search} may be modified to a backward
		search by making the substitutions shown in
		Table~\ref{tab:switiching_between_forward_and_backward_search}.%following substitutions:

		%\begin{align}
		%	\begin{split}
		%		\state_{\goal} &\leftrightarrow \state_{\initial} \\
		%		\statespace_{\initial} &\leftrightarrow \statespace_{\goal} \\
		%		\invaction &\leftrightarrow \action\\
		%		\invactionspace &\leftrightarrow \actionspace\\
		%		f^{-1} &\leftrightarrow f
		%	\end{split}
		%\end{align}

		\begin{table}[ht]
			\centering
			\begin{tabular}{c  c}
				\toprule
				Forward Search 			& Backward Search\\
				\midrule
				$\state_{\initial}$		&	$\state_{\goal}$ 			\\
				$\statespace_{\goal}$	&	$\statespace_{\initial}$	\\
				$\action$ 				&	$\invaction$				\\
				$\actionspace$ 			&	$\invactionspace$			\\
				$f$ 					&	$f^{-1}$					\\
				%\bottomrule
			\end{tabular}
			\caption{Switching Between Forward and Backward Search}%
			\label{tab:switiching_between_forward_and_backward_search}
		\end{table}


		Finally, it is worth noting that changing the type of priority queue
		$\queue$ in Algorithm~\ref{alg:general_forward_search} can be modified
		to obtain different types of search algorithms. For instance, Breadth
		First Search is obtained by setting $\queue$ to a \gls{fifo} queue,
		whereas Depth First Search may be obtained by setting $\queue$ to a
		stack~\cite[][page 35]{bib:planning:planning_algorithms}. The well-known
		Dijkstra and $A^*$ algorithms can be seen as specialisations of
		Algorithm~\ref{alg:general_forward_search}.

		\todo{mention bidirectional search}

	\subsection{Continuous Case}%
	\label{sec:continuous_case}

		\subsubsection{Sampling-Based Motion Planning}%
		\label{sec:sampling_based_motion_planning}

			Sampling methods avoid explicit construction of
			$\configurationspace_{\obstacleregion}$. The idea is that they
			instead sample $\configurationspace$ while looking for a path. These
			algorithms cannot detect whether a path does not exist, and instead
			run forever.

			\paragraph{Sampling Strategies}%
			\label{sec:sampling_strategies}

				These algorithms differ in the way that they sample
				$\configurationspace$. As they sample, they may build a
				topological graph \( \topologicalgraph(\vertex, \edge \in
				\configurationspace_{\freeregion}) \) which can be used with the
				algorithms from Section~\ref{sec:discrete_case} to obtain a path
				$\pathsym$.  Sampling strategies are required to produce dense
				samples as they progress in time.  What follows is a brief
				overview of possible sampling methods.

				\begin{itemize}

					\item Random Sampling

						This technique generates directions and orientations
						separately from different random distributions.  A
						random quaternion $\quaternion$ is generated from the
						formula\cite{bib:planning:planning_algorithms}:

						\begin{equation}
							\quaternion =
								\left(
									\sqrt
									{%
										1 - u_1
									}
									\sin
										2\pi u_2
									,
									\sqrt
									{%
										1 - u_1
									}
									\cos
										2\pi u_2
									,
									\sqrt
									{%
										u_1
									}
									\sin
										2\pi u_3
									,
									\sqrt
									{%
										u_1
									}
									\cos
										2\pi u_3
								\right)
						\end{equation}

						Where
						\(
							(u_1, u_2, u_3) \in [0, 1]
						\)
						are chosen from a uniform distribution.

						The components
						\(
							\point_1, \ldots, \point_n
						\)
						of a direction $\point$ may be drawn from a zero-mean
						Gaussian distribution. The direction is normalised with:

						\begin{equation}
							\frac{\point}{\norm{\point}}
						\end{equation}

						and is used to choose which direction to take a step in
						for the next sample.

					\item Low-Dispersion Sampling

						Low-Dispersion Sampling is a bit more sophisticated than
						Random Sampling. It tries to place the samples such that
						the largest uncovered area is minimised. Obviously, such
						samples cannot be perfectly random, but they tend to
						work better for motion planning.

						\todo{these symbols are not in nomenclature}

						Optimal dispersion is produced by partitioning
						$\configurationspace$ into cubes and placing the sample
						at the centre of each cube. Given $k$ samples, the
						number of cubes per axis is then simply
						\(
							\floor*{k^{\frac{1}{\dim{\configurationspace}}}}
						\).

					%\item Low-Discrepancy Sampling

					\todo{Maybe mention low-discrepancy sampling p 221}

					%\item Incremental Sampling and Search

					\todo{Incremental Sampling and Search}

					\item Randomised Potential Fields

						Sampling techniques can get stuck in local minima.
						Randomised Potential Fields attempt to escape such
						minima.

						These algorithms have an attractive term which relates
						to the distance to $\configuration_{\goal}$, as well as
						a repulsive term which acts as a penalty on
						configurations that are too close to
						$\configurationspace_{\obstacleregion}$. The idea is
						that the algorithms perform a Best First Search search
						until they detect that they have gotten stuck. When this
						happens, the algorithm performs a random walk through
						$\configurationspace$ and  then performs Best First
						Search again. If the algorithm gets stuck too many
						times, it returns back to a random previous point
						$\configuration$ and starts over at this point.

						A negative point of such algorithms is that they tend to
						have a large amount of tuning parameters.

					\item \glspl{rdt}

						\glspl{rdt} incrementally construct a tree in
						$\configurationspace$. The resolution of the tree
						increases with time without the need for tuning
						parameters. This makes them analogous in a sense to
						space-filling curves. The well known \gls{rrt}
						algorithms can be considered as a special case of
						\glspl{rdt}. The basic \gls{rdt} algorithm is shown in
						Algorithm~\ref{alg:basic_rdt}.

						\begin{algorithm}[ht]
							\caption{Basic \gls{rdt} Algorithm}%
							\label{alg:basic_rdt}
							\begin{algorithmic}[1]
								\Procedure{BasicRDT}{$\configuration_{\initial}$}
									\State{} Initialise $\topologicalgraph$ with $\configuration_{\initial}$
									\While{$\configuration_{\goal}$ not reached}%
										\State{} $\sample \gets \code{SAMPLE}(\configurationspace)$ 								\label{alg:basic_rdt:sample}%
										\State{} $\configuration_1 \gets \code{NEAREST}(\swath(\topologicalgraph),\sample)$ 		\label{alg:basic_rdt:nearest}%
										\State{} $\configuration_2 \gets \code{STOP\_CONFIGURATION}(\configuration_1, \sample)$ 	\label{alg:basic_rdt:stop}%
										\If{$\configuration_1 \neq \configuration_2$}%
											\State{} $\topologicalgraph$.\code{add\_vertex}$(\configuration_2)$ 					\label{alg:basic_rdt:add_vertex}%
											\State{} $\topologicalgraph$.\code{add\_edge}$(\configuration_1, \configuration_2)$ 	\label{alg:basic_rdt:add_edge}%
										\EndIf{}
									\EndWhile{}
								\EndProcedure{}
							\end{algorithmic}
						\end{algorithm}

						The algorithm attempts to connect a sample
						$\sample\in\configurationspace$ to the nearest point
						$\configuration_1$ in the swath of the topological
						graph, $\swath(\topologicalgraph)$, in
						Line~\ref{alg:basic_rdt:nearest}. Note that this may add
						a new vertex to $\topologicalgraph$ if
						$\configuration_1$ is closer to an edge
						$\edge\in\topologicalgraph$ than a vertex
						$\vertex\in\topologicalgraph$.
						Line~\ref{alg:basic_rdt:stop} picks a point
						$\configuration_2$ along the direction
						$\vecline{\configuration_1}{\sample}$ as close as
						possible to $\sample$, but stopping short of any
						obstacles. This point is then added to
						$\topologicalgraph$.

				\end{itemize}

			\paragraph{Connecting $\configuration_{\initial}$ and
			$\configuration_{\goal}$ to the grid}%
			\label{sec:connecting_initial_configuration_and_goal_configuration_to_the_grid}

				Sampled points are not likely to coincide directly with
				$\configuration_{\initial}$ or $\configuration_{\goal}$.
				Instead, a region around these points must be chosen. The points
				are connected to any sampled points in this region using a
				method such as that described in
				Section~\ref{sec:path_segment_collision_detection}. The size of
				this region can for instance be based on the greatest distance
				between a sampled point and its farthest neighbour.

			\paragraph{Smoothing Random Paths}%
			\label{sec:smoothing_random_paths}

				THERE IS A FORMULA IN SECTION 5.4.3 OF NOTES

		\subsubsection{Combinatorial Motion Planning}%
		\label{sec:combinatorial_motion_planning}

			Combinatorial motion planning methods differ from the sampling-based
			methods of Section~\ref{sec:sampling_based_motion_planning} in that
			they are complete algorithms. That is, these algorithms are
			guaranteed to find a path in finite time if it exists, or report
			that no path exists.

			These algorithms work by decomposing $\configurationspace$ into
			cells $\cell$ that are guaranteed to be free from collisions. That
			is, the algorithms guarantee that:

			\begin{equation}
				\point\in\configurationspace_{\freeregion},
				\quad
				\forall\point\in\cell \, \text{and} \, \forall\cell\in\world
			\end{equation}

			An example cell decomposition for $\world\subseteq\Re^2$ can be seen
			in Figure~\ref{fig:example_2d_cell_decomposition}.

			\begin{figure}[hb]
				\centering
				\def\svgwidth{\columnwidth}
				\import{res/img/}{2d_cell_decomposition.pdf_tex}
				\caption[Example 2D Cell Decomposition]
				{%
					Example 2D Cell Decomposition 
					(adapted from~\cite[][page 269]
						{bib:planning:planning_algorithms})
				}%
				\label{fig:example_2d_cell_decomposition}
			\end{figure}

			The connectivity of the cells is encapsulated in a graph
			$\topologicalgraph$ which may be searched for paths using the
			methodologies of Section~\ref{sec:discrete_case}.

			It should be noted that~\cite{bib:planning:planning_algorithms}
			warns that combinatorial motion planning methods may be impractical
			in practice. They are also not suitable for differential
			constraints.  As such, they are not explored further in this report.
			However, a good reference for such algorithms can be found
			in~\cite{bib:planning:robot_motion_planning}.

	\todo{Maybe mention Feedback Planning as a subsection}

	\subsection{Planning in the Presence of Differential Constraints}%
	\label{sec:planning_in_the_presence_of_differential_constraints}

		Planning may be subject to differential constraints. Such constraints
		are often expressed in an implicit form:

		\begin{equation}
			g(\configuration, \dot{\configuration}, \ldots, \tdern{\configuration}{n})
				\relop 0
			\label{eq:implicit_dif_constraint}
		\end{equation}

		Such a constraint may for instance indicate that the velocity may not
		exceed a certain threshold. In such a case,
		equation~\ref{eq:implicit_dif_constraint} takes the form
		$\norm{\dot{\configuration}} < \threshold$.

		However, planning algorithms require differential constraints to be
		expressed in the parametric form:

		\begin{equation}
			\dot{\configuration} = f(\configuration, \action)
			\label{eq:parameteric_dif_constraint}
		\end{equation}

		The state-space representation techniques from control theory may be
		used to convert the representation in
		Equation~\ref{eq:implicit_dif_constraint} to that in
		Equation~\ref{eq:parameteric_dif_constraint}. As a simple example,
		consider $k$ equations of the form:

		\begin{equation}
			g_1(\configuration_1)\dot{\configuration}_1 + \cdots +
				g_n(\configuration_n)\dot{\configuration}_n
			=
			0
		\end{equation}

		These may be converted to the form in
		Equation~\ref{eq:parameteric_dif_constraint} by making the
		substitutions:

		\begin{align}
				\dot{\configuration_{\indexi}} &= \action_{\indexi} 					\quad&&\forall\indexi\in [1, \dim{\configurationspace} - k] \\
				\dot{\configuration_{\indexi}} &= f_{\indexi}(\configuration, \action)	\quad&&\forall\indexi\in [\dim{\configurationspace} - k + 1,\dim\configurationspace]
		\end{align}

		Where $f_{\indexi}$ is found by simply solving the functions for
		$\dot{\configuration_{\indexi}}$.

		\subsubsection{Use of Phase Space}%
		\label{sec:use_of_phase_space}

			When higher-order differential constraints are imposed on the
			problem, it is of benefit to express the system in phase space
			$\phasespace$ instead of configuration space $\configurationspace$.
			In general, the relation between the dimensions of these spaces is
			given by:
			\todo{discuss phase space}

			\begin{equation}
				\dim\phasespace = k\dim\configurationspace
			\end{equation}

			Where $k$ is the highest-order of the differential constraints.

		\subsubsection{Sampling Approaches}%
		\label{sec:sampling_approaches}

			One approach to path planning with differential constraints requires
			the selection of a discrete set of motion primitives:

			\begin{equation}
				\actionspace_{\discrete} \subset \actionspace
			\end{equation}

			To each action $\action_{\discrete} \in \actionspace_{\discrete}$ is
			associated a time duration $\timesym_{\discrete}$.

			To find successive states, sampling algorithms use the discrete
			state transition function:

			\begin{equation}
				\state_{\indexk + 1} = f_{\discrete}(\state_{\indexk},
					{\action_{\discrete}}_{\indexk})
			\end{equation}

			Therefore, the sampling algorithm needs to sample both $\phasespace$
			and $\actionspace$. The methods mentioned in
			Section~\ref{sec:sampling_based_motion_planning} are generally used
			to sample these spaces.

			Collision detection from Section~\ref{sec:collision_detection} is
			used to test these samples. However, the phase constraints need to
			be tested separately. Since
			$\phasespace_{\regionOfInevitableCollision}$ cannot be checked
			directly, the general method is to test that a state $\state$ is
			farther than some threshold $\threshold$ from each constraint
			boundary.

			In practice, \gls{rdt} methods tend to return feasible trajectories
			in phase space with relatively few samples. However, these paths
			tend to be suboptimal.



