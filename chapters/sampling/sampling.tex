\chapter{Sampling}%
\label{chap:sampling}

	The designed architecture\todo{wording} uses a sampling approach for path
	planning. Path planning was first investigated in two dimensions before
	generalising to the spatial case.\todo{wording again} The sampling algorithm
	used is a variant of the well-known \gls{rrt} algorithm.

	Due to the topology of the class of \gls{cdpr} considered, the sampling
	algorithm does not need to sample in configuration space, but may instead
	sample poses directly. This is due to the fact that there is a one-to-one
	correlation between end-effector pose and robot configuration.

	\section{Algorithm Overview}%
	\label{sec:algorithm_overview}

		The pose $\pose$ of the robot $\robot$ is described as a translation
		vector $\transvec$ combined with a quaternion $\quaternion$:

		\begin{equation}
			\pose = (\transvec, \quaternion)
		\end{equation}

		Furthermore, the algorithm defines a graph $\topologicalgraph$ of poses.
		During each iteration, the algorithm samples a new pose,
		$\pose_{\indexi}$ such that:

		\begin{equation}
			\robot(\pose_{\indexi}) \not\in
			\configurationspace_{\obstacleregion}
		\end{equation}

		and attempts to add it to the graph:

		\begin{equation}
			\topologicalgraph_{\indexi + 1} \leftarrow
				\topologicalgraph_{\indexi} \cup \pose_{\indexi}
		\end{equation}

		in such a way that:

		\begin{equation}
			\exists \pose_{\indexj} \in \topologicalgraph_{\indexi}
				\quad\suchthat\quad
				\vecline{\pose_{\indexi}}{\pose_{\indexj}} \notin
				\configurationspace_{\obstacleregion}
		\end{equation}

		This last line states that the new sampled pose may be connected to some
		other pose already in the graph in such a way that the path connecting
		the two poses is free of collisions.

		At the same time, at each iteration, the algorithm attempts to add the
		goal pose $\pose_{\goal}$ to $\topologicalgraph$. If this is
		successfully executed, then a path has been found and the algorithm
		terminates. A high-level overview of the algorithm can be found in
		Algorithm~\ref{alg:sampling_planning_overview}.

		\begin{algorithm}[ht]
			\caption{Sampling Planning Overview}%
			\label{alg:sampling_planning_overview}
			\begin{algorithmic}[1]
				\Procedure{Sample\_Search}{$\robot, \obstacle_1, \ldots, \obstacle_n$}
					\State{}$\topologicalgraph = \emptyset \cup \pose_{\initial}$
					\While{$\pose_{\goal} \notin \topologicalgraph$}
						\Repeat{}
							\State{}$\pose_\text{sampled} \leftarrow
							\code{sample\_pose}$\label{alg:sampling_planning_overview:sample_pose}
						\Until{$\robot(\pose) \notin \configurationspace_{\obstacleregion}$}
						\State{}
							\(
								\pose_{\text{neighbour}} =
								\argmin_{\pose_{\indexi} \in
								\topologicalgraph}\dist(\pose_\text{sampled}, \pose_{\indexi})
							\)
						\State{}$\pose_\text{new} =
							\code{farthest\_collision\_free\_point}(\pose_{\text{sampled}},
							\pose_{\text{neighbour}})$\label{alg:sampling_planning_overview:farthest_collision_free_point_sampled}
						\State{}$\code{connect}(\pose_\text{neighbour},
							\pose_\text{new})$
						\State{}$\pose_\text{new} =
							\code{farthest\_collision\_free\_point}(\pose_{\text{new}},
							\pose_{\text{\goal}})$\label{alg:sampling_planning_overview:farthest_collision_free_point_goal}
						\If{$\pose_\text{new} == \pose_{\goal}$}
							\State{}$\code{connect}(\pose_{\goal},
								\pose_\text{new})$
						\EndIf{}
					\EndWhile{}
				\EndProcedure{}
			\end{algorithmic}
		\end{algorithm}

	\section{Sample Strategy}%
	\label{sec:sample_strategy}

		Line~\ref{alg:sampling_planning_overview:sample_pose} of
		Algorithm~\ref{alg:sampling_planning_overview} samples a pose from the
		configuration space of the robot in the following manner:

		\begin{enumerate}

			\item

				A translation vector $\transvec$ is drawn from a normal
				distribution such that:
				\label{item:sample_strategy:translation}

				\begin{enumerate}

					\item

						The median of the distribution is the centre of the
						workspace.

					\item

						The edges of the workspace are three standard deviations
						away from the median.
				\end{enumerate}

			\item

				An angle $\theta$ is drawn from a normal distribution with
				median $\pi/2$ and standard deviation $\pi/6$.

				\label{item:sample_strategy:angle}

			\item

				A quaternion is built from the formula:

				\begin{equation}
					\quaternion = 0\vec{i} + \sin(\theta/2)\vec{j} + 0\vec{k} +
						\cos(\theta/2)
				\end{equation}

				\label{item:sample_strategy:quaternion}

				%This produces a rotation of angle $\theta$ around the $y$
				%axis.\todo{explain that y axis is pointing up}

			\item

				The pose $\pose = (\transvec, \quaternion)$ is returned.

		\end{enumerate}

		\subsection{Justification of Sampling Strategy}%
		\label{sec:justification_of_sampling_strategy}

			\glspl{cdpr} have a higher capacity margin towards the centre of
			their workspace\todo{cite something here}. This led to the decision
			to use a normal distribution to sample translations as described in
			Item~\ref{item:sample_strategy:translation} above. In doing so,
			the sampling algorithm has a higher probability to choose
			translations closer to the centre of the workspace, thereby
			increasing the average stability of the trajectory found.

			Items~\ref{item:sample_strategy:angle}
			and~\ref{item:sample_strategy:quaternion} in the list above generate
			a rotation $\theta$ around the $y$-axis. The reason that rotations
			are only drawn around the $y$ axis is two-fold. The first reason is
			that experimentation has shown that the architecture performs faster
			when only drawing rotations around a single axis\todo{back this up
			with numbers}. The second reason is that, by only drawing rotations
			around the $y$ axis, the robot is guaranteed to be upright during
			its trajectory. This produces simpler trajectories, as generating
			completely random quaternions would have the robot change its
			orientation unpredictably.

			The mean and standard deviation as defined in
			Item~\ref{item:sample_strategy:angle} are chosen such that 99.7\% of
			the sampled rotations lie within the range $\theta \in [0, \pi]$.
			The effect of using a uniform distribution within this range instead
			of the distribution of Item~\ref{item:sample_strategy:angle} was
			also investigated. This, however, was deemed an inefficient
			approach, as the end-effector was found to have a tendency to
			unnecessarily swing back and forth around the $y$-axis as it
			progressed through its trajectory. By instead biassing the
			end-effector's orientation towards a certain median position, the
			need for a post-processing operation to simplify the orientation's
			progression was eliminated.

			Following this approach, given an arbitrary start and end pose, the
			architecture finds a path through several poses in such a way that,
			while moving from the start pose to the first sampled pose, the
			robot is turned upright. Then, while in the middle of its
			trajectory, the robot stays upright. Finally, as the robot
			approaches its final pose, it performs any required arbitrary
			rotations to reach the desired goal pose. This is shown
			schematically in Figure~\ref{fig:pose_sampling}.

			\begin{figure}[hb]
				\missingfigure{}
				\caption{Pose Sampling}%
				\label{fig:pose_sampling}
			\end{figure}


	\section{Path Checking}%
	\label{sec:path_checking}

		\begin{sloppypar}

			There is no guarantee that a sampled pose $\pose_\text{sampled}$ can
			be connected directly to its nearest neighbour
			$\pose_\text{neighbour} \in \topologicalgraph$. \todo{Put figure
			explaining why} Therefore, the calls to
			$\code{farthest\_collision\_free\_point}$ in lines
			Lines~\ref{alg:sampling_planning_overview:farthest_collision_free_point_sampled}
			and~\ref{alg:sampling_planning_overview:farthest_collision_free_point_goal}
			of Algorithm~\ref{alg:sampling_planning_overview} attempt to
			guarantee that there is no collision between these points.

		\end{sloppypar}

		This is done by discretising points between $\pose_\text{neighbour}$ and
		$\pose_\text{sampled}$ in a straight-line fashion and returning the
		point farthest from $\pose_\text{neighbour}$ before any collision is
		detected. This is summarised in
		Algorithm~\ref{alg:farthest_collision_free_point}.

		\begin{algorithm}[ht]
			\caption{Farthest Collision Free Point}%
			\label{alg:farthest_collision_free_point}
			\begin{algorithmic}[1]
				\Procedure{Farthest\_Collision\_Free\_Point}{$\pose_1, \pose_2$}
					\State{}$\code{dist\_to\_travel} = \dist(\pose_1, \pose_2)$
					\State{}$\code{dist\_travelled} = 0$
					\State{}$\pose_\text{intermediate} = \pose_1$
					\State{}$\pose_\text{prev-intermediate} = \pose_1$
					\While{$\code{dist\_travelled} < \code{dist\_to\_travel}$}
						\State{}
							\(
								\pose_\text{intermediate} =
								\pose_1 +
								\code{dist\_travelled}/\code{dist\_to\_travel}
								(
									\pose_2 - \pose_1
								)
							\)
						\If{\robot($\pose_\text{intermediate}) \in \configurationspace_{\obstacleregion}$}
							\State{}$\pose_\text{intermediate} =
								\pose_\text{prev-intermediate}$
							\State{}break
						\EndIf{}
						\State{}$\code{dist\_travelled} =
							\code{dist\_travelled} + \Delta\configuration$
						\State{}$\pose_\text{prev-intermediate} =
							\pose_\text{intermediate}$
					\EndWhile{}
					\If{$\code{dist\_travelled} > \code{dist\_to\_travel}$}
						\State{}return $\pose_2$
					\EndIf{}
					\State{}return $\pose_\text{intermediate}$
				\EndProcedure{}
			\end{algorithmic}
		\end{algorithm}

		The term $\Delta\configuration$ in
		Algorithm~\ref{alg:farthest_collision_free_point} is an increment that
		determines the resolution at which paths are checked. Its value must be
		chosen such that the algorithm executes quickly, but does not jump over
		obstacles. Its value essentially determines a sphere of radius
		$\Delta\configuration$ around every sampled pose $\pose$ within which it
		is not certain if there is a collision or not.

		This uncertainty is negated by creating virtual obstacles that are
		larger than the actual obstacles by a value
		greater than $\Delta\configuration$. That way, if there is a collision
		in the uncertain points between $\pose_1$ and $\pose_2$, it will be a
		collision with a virtual obstacle, but not with the real obstacle.
		\todo{When this is implemented, discuss it better}

	\section{Distance Measure}%
	\label{sec:distance_measure}

		Both Algorithm~\ref{alg:sampling_planning_overview}
		and~\ref{alg:farthest_collision_free_point} require to measure the
		distance between two poses, $\dist(\pose_1, \pose_2)$. This poses a
		problem, however, as a pose is a member of the special euclidean group,
		$\pose \in \specialEuclideanGroup{3}$. There is no one way to measure
		distances in this set and an arbitrary measure is often required. There
		is also the problem that the units used for rotations and translations
		differ.

		Several different measures are often used in these cases. One is to
		simply define the distance as the translational distance between two
		poses:

		\begin{equation}
			\dist(\pose_1, \pose_2) =
				\norm{%
					\pose_2.\transvec - \pose_1.\transvec
				}
			\label{eq:euclidean_distance}
		\end{equation}

		\todo{Add radius of gyration discussion here}

		This thesis proposes to instead measure distances in cable-space. This
		has the following advantages:

		\begin{itemize}

			\item

				Dimensionally homogeneous. Since each pose is related directly
				to the length of the cable-space vector, both the translation
				and orientation of a pose can be measured using meters.

			\item

				Direct correlation to actuators. The change in length of the
				cables relates directly to how much the actuators have to act on
				the cables. Using the cable-space vector as a distance measure
				means that the distance exactly encodes the amount of actuation
				required to move from one pose to another.
				\todo{wording}

		\end{itemize}

		The cable-space vector, $\cablelengths$, can be found from the indirect
		geometric model of the \gls{cdpr}:

		\begin{equation}
			\cablelengths = \invgeometricmodel(\pose)
		\end{equation}

		The distance function is then taken as:\todo{make sure this is correct,
		and implement it in the code}

		\begin{equation}
			\dist(\pose_1, \pose_2) =
				\norm{%
					\invgeometricmodel(\pose_2) - \invgeometricmodel(\pose_1)
				}
			\label{eq:distance_measure}
		\end{equation}

